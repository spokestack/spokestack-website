---
title: Test with Real People
navId: Test with Real People
description: Some ways to test with real people
draft: false
---

Remember the survey and one-sheets you created while [getting to know your audience](/docs/Design/get-to-know-your-audience)? Refer to your findings from both when figuring out what and whom to test your app with. What's your target audience’s comfort level with multi-modal interfaces and/or voice? We recommend testing a beta version of your app rather than a prototype.

Here’s why:

# **Challenges of testing multi-modal prototypes**

There are many script prototyping tools, but few that account for the addition of visuals. The three main tools we have tried include Sketch, Invision, and Adobe XD.

## Sketch & Invision

## Adobe XD

# **Tips for testing a multi-modal interface**

Test how they use your app in different contexts where possible. Do this either unmoderated or moderated. You want people to test your app on their phones, not in a browser. Include public test environments and candidates with varying accents.

- How do they interact with your app outside of your experience map?
- What types of things are they asking for? Are these accounted for in your experience?

## **Unmoderated (remote)**

We recommend this if you're limited by time, manpower, and/or budget. Unmoderated candidates tend to give more honest feedback. One disadvantage is that you’re unable to help the user when they get stuck or ask follow-up questions. For remote testing, we use “task completion” tests for iOS, Android, or both on [UserBob](https://userbob.com/).

1. **Write research questions.**
   These should include uncertainties you want to put to rest. Don’t expose these to your users. Think of these as internal measurement tools. Here are some examples:

- Do users understand the concept?
- Do they know what to ask or say? Are they asking the right questions? If not, what are they asking?
- Are they running into any errors?
- Where applicable, do they understand that your app is wakeword-enabled? Did they use this feature? If not, why?

2. **Provide a url for testing.**
   This could include a link to the iTunes Store or Google Play Store. If testing a beta version of an app, send them an invitation before testing. Provide instructions not to download before the test.

3. **Write a list of tasks based on your research questions, no more than 15.**
   Include follow-up questions to tasks you want further clarity on. A good follow-up question to ask before a user completes a task is: What would you expect to happen here? Try to avoid questions that project future behavior. It’s hard to get honest feedback from projections.

4. **Include a description of what the user should do.**
   Think of this as your intro. Add this before your list of tasks. Here’s an example:

> We’re asking you to test a mobile app that lets you record different types of fitness activities. This is a work in progress, so if something doesn’t work, explain what you would expect to happen and move on. We’re testing the app, not you — no need to worry about making mistakes.
>
> Below are a series of tasks. Try completing each task using the app on your phone. As much as possible, think out loud as you go along: say what you’re looking at, what you’re trying to do, and what you’re thinking.

5. **Iterate on your tasks and description if users get hung up on phrasing or if there's a bug.**

Remember, you’re collecting qualitative data, not quantitative. If you start to see users saying the same things, finish up that round of testing. Move on to tweaking your product before the next round of testing.

## **Moderated**

You’re able to ask more follow-up questions and improvise, but feedback can sometimes be less honest. We recommend this if you have more time and are able to meet your users face-to-face, either remote or colocated.

Use your survey to recruit candidates. For colocated tests, make sure candidates are local. Allow yourself a week or more to schedule time to meet one-on-one with candidates. We use Calendly and/or Google Calendar to schedule meetings and share testing times with teammates.

Emailing your candidates.

Gather a list of tasks that you’re the most unsure about, no more than 10. What are you trying to learn from these candidates? Add these research questions to the top of your script. Write a test script. Here’s a sample to get you started.

1. **Write research questions.**
   These should include product uncertainties you want to put to rest. Don’t expose these to your users. Think of these as internal measurement tools. Here are some examples:

- Do users understand the concept?
- Do they know what to ask or say? Are they asking the right questions? If not, what are they asking?
- Are they running into any errors?
- Where applicable, do they understand that your app is wakeword-enabled? Did they use this feature? If not, why?

2. **Provide a url for testing.**
   This could include a link to the iTunes Store or Google Play Store. If testing a beta version of an app, send them an invitation before testing. Provide instructions not to download before the test. It’s best for users to use their own device for testing to eliminate unforeseen barriers. Bring a few extra mobile devices for testing as a back-up in case users are unable to download your app.

3. **Write a list of tasks based on your research questions, no more than 15.**
   Include follow-up questions to tasks you want further clarity on. A good follow-up question to ask before a user completes a task is: What would you expect to happen here? Try to avoid questions that project future behavior. It’s hard to get honest feedback from projections.

4. **Include a description of what the user should do.**
   This of this as your intro. Add this before your list of tasks. Here’s an example:

> We’re asking you to test a mobile app that lets you record different types of fitness activities. This is a work in progress, so if something doesn’t work, explain what you would expect to happen and move on. We’re testing the app, not you — no need to worry about making mistakes.
>
> Below are a series of tasks. Try completing each task using the app on your phone. As much as possible, think out loud as you go along: say what you’re looking at, what you’re trying to do, and what you’re thinking.

5. **Iterate on your tasks and descriptions if users get hung up on phrasing or if there's a bug.**

Remember, you’re collecting qualitative data, not quantitative. If you start to see users saying the same things, finish up that round of testing. Move on to tweaking your product before the next round of testing.
